# WORK: Create Integration Tests (v4 AI-Native)
# Self-contained test suite for EPIC-TIDE ecosystem validation

WORK:
  id: create-integration-tests
  what: "Create comprehensive test suite validating EPIC-TIDE system end-to-end"
  
  # CONTEXT - Task environment
  context:
    location: Testing and validation phase
    prerequisites:
      - "Database schema implemented and running"
      - "API endpoints functional"
      - "Vocabulary definitions established"
      - "Test framework available (Jest/Mocha)"
    outputs:
      - "Complete integration test suite"
      - "Test data fixtures and cleanup utilities"
      - "Performance benchmark tests"
      - "Error scenario validation tests"
    dependencies: ["design-database-schema", "implement-post-api", "define-vocabulary"]
    
  # KNOWLEDGE - Critical testing information
  knowledge:
    - "Integration tests must validate entire WORK→PATH→TIDE→PATTERN flow"
    - "Vocabulary enforcement prevents invalid data states"
    - "Concurrent TIDE prevention is critical for data integrity"
    - "Vector similarity search requires actual embeddings to test properly"
    - "Test isolation requires database transaction rollbacks or cleanup"
    - "Performance tests should use realistic data volumes (1k+ records)"
    - "Error scenarios are as important as success scenarios"
  
  # EXECUTION
  how:
    - "Set up test database with schema and sample data"
    - "Create vocabulary validation tests for all controlled fields"
    - "Test complete WORK→PATH→TIDE flow with real scenarios"
    - "Implement pattern extraction testing with multiple TIDEs"
    - "Add error handling tests for all failure modes"
    - "Create concurrent TIDE prevention tests"
    - "Add performance benchmarks for vector search"
  
  metrics:
    - "All EPIC-TIDE components have integration tests"
    - "End-to-end flow validated with real data"
    - "Edge cases and error scenarios covered"
    - "Performance benchmarks established"
  
  # LEARNINGS - From testing implementation
  learnings:
    - source: "Initial test setup"
      learning: "Test database needs actual vector embeddings, not null values"
    - source: "Vocabulary testing"
      learning: "Enum validation at database level catches more errors than application level"
    - source: "Concurrent testing"
      learning: "Race conditions best tested with Promise.all() simulating parallel requests"
    - source: "Pattern testing"
      learning: "Pattern extraction requires minimum 3 TIDEs to generate meaningful results"
  
  # TROUBLESHOOTING - Common testing issues
  troubleshooting:
    - issue: "Vector similarity tests fail with null embeddings"
      symptoms: "Cosine similarity returns unexpected results"
      solution: "Generate actual embeddings using test embedding service"
      prevention: "Include embedding generation in test data setup"
    
    - issue: "Concurrent TIDE tests are flaky"
      symptoms: "Tests pass individually but fail when run together"
      solution: "Add proper test isolation with database cleanup"
      prevention: "Use transactions with rollback for each test case"
    
    - issue: "Performance tests vary wildly"
      symptoms: "Same query shows 100ms to 2000ms response times"
      solution: "Warm up database with query before timing, run multiple iterations"
      prevention: "Include database statistics update in test setup"
    
    - issue: "Pattern extraction tests don't find patterns"
      symptoms: "Pattern endpoint returns empty results"
      solution: "Ensure test data has enough similar TIDEs to extract patterns"
      prevention: "Create test fixtures with intentionally similar execution sequences"
  
  # COMPLETE IMPLEMENTATION
  artifacts:
    test_suite: |
      // Integration Test Suite for EPIC-TIDE
      
      const request = require('supertest');
      const app = require('../src/app');
      const db = require('../src/database');
      const embeddings = require('../src/embeddings');
      
      describe('EPIC-TIDE Integration Tests', () => {
        
        beforeEach(async () => {
          // Clean test database
          await db.query('TRUNCATE TABLE patterns, tides, paths, works CASCADE');
        });
        
        describe('Vocabulary Enforcement', () => {
          test('should reject invalid status values', async () => {
            const response = await request(app)
              .post('/api/works')
              .send({
                what: 'Test work',
                how: ['step 1'],
                metrics: ['metric 1'],
                status: 'invalid_status' // Should be rejected
              });
            
            expect(response.status).toBe(400);
            expect(response.body.error).toContain('Invalid status');
          });
          
          test('should accept valid status values', async () => {
            const validStatuses = ['pending', 'in_progress', 'completed', 'failed'];
            
            for (const status of validStatuses) {
              const response = await request(app)
                .post('/api/works')
                .send({
                  what: 'Test work',
                  how: ['step 1'], 
                  metrics: ['metric 1'],
                  status
                });
              
              expect(response.status).toBe(201);
            }
          });
        });
        
        describe('Complete WORK→PATH→TIDE Flow', () => {
          test('should execute complete workflow', async () => {
            // 1. Create WORK
            const workResponse = await request(app)
              .post('/api/works')
              .send({
                what: 'Setup test project',
                how: ['Create package.json', 'Install dependencies'],
                metrics: ['Project created', 'Dependencies installed']
              });
            
            expect(workResponse.status).toBe(201);
            const workId = workResponse.body.work_id;
            
            // 2. Create PATH with WORK
            const pathResponse = await request(app)
              .post('/api/paths')
              .send({
                what: 'Project setup path',
                works: [workId],
                metrics: ['All setup completed']
              });
            
            expect(pathResponse.status).toBe(201);
            const pathId = pathResponse.body.path_id;
            
            // 3. Start TIDE
            const tideResponse = await request(app)
              .post('/api/tides')
              .send({
                path_id: pathId,
                attempt: 1
              });
            
            expect(tideResponse.status).toBe(201);
            const tideId = tideResponse.body.tide_id;
            
            // 4. Execute WORK in TIDE
            const executeResponse = await request(app)
              .patch(`/api/tides/${tideId}`)
              .send({
                status: 'in_progress',
                execution: { [workId]: 'in_progress' }
              });
            
            expect(executeResponse.status).toBe(200);
            
            // 5. Complete TIDE
            const completeResponse = await request(app)
              .patch(`/api/tides/${tideId}`)
              .send({
                status: 'completed',
                execution: { [workId]: 'completed' },
                outcome: 'success',
                learnings: 'Project setup went smoothly',
                metrics_achieved: { 'Project created': true, 'Dependencies installed': true }
              });
            
            expect(completeResponse.status).toBe(200);
            
            // Verify final state
            const finalTide = await request(app).get(`/api/tides/${tideId}`);
            expect(finalTide.body.outcome).toBe('success');
            expect(finalTide.body.completed_at).toBeTruthy();
          });
        });
        
        describe('Concurrent TIDE Prevention', () => {
          test('should prevent multiple active TIDEs on same PATH', async () => {
            // Create PATH
            const pathResponse = await request(app)
              .post('/api/paths')
              .send({
                what: 'Test path',
                works: [],
                metrics: ['Test completed']
              });
            
            const pathId = pathResponse.body.path_id;
            
            // Start first TIDE
            const tide1 = await request(app)
              .post('/api/tides')
              .send({
                path_id: pathId,
                attempt: 1
              });
            
            expect(tide1.status).toBe(201);
            
            // Try to start second TIDE on same PATH
            const tide2 = await request(app)
              .post('/api/tides')
              .send({
                path_id: pathId,
                attempt: 1
              });
            
            expect(tide2.status).toBe(409); // Conflict
            expect(tide2.body.error).toContain('active TIDE already exists');
          });
        });
        
        describe('Pattern Extraction', () => {
          test('should extract patterns from similar TIDEs', async () => {
            // Create multiple similar TIDEs with same execution pattern
            const pathId = await createTestPath();
            
            const similarTides = [];
            for (let i = 1; i <= 3; i++) {
              const tideResponse = await request(app)
                .post('/api/tides')
                .send({ path_id: pathId, attempt: i });
              
              const tideId = tideResponse.body.tide_id;
              
              // Complete with similar pattern
              await request(app)
                .patch(`/api/tides/${tideId}`)
                .send({
                  status: 'completed',
                  outcome: 'success',
                  execution: { 'work1': 'completed', 'work2': 'completed' },
                  adaptations: [{ type: 'parameter_adjustment', reason: 'timeout too low' }],
                  learnings: 'Need longer timeout for this work type'
                });
              
              similarTides.push(tideId);
            }
            
            // Extract patterns
            const patternResponse = await request(app)
              .post('/api/patterns/extract')
              .send({ tide_ids: similarTides });
            
            expect(patternResponse.status).toBe(201);
            expect(patternResponse.body.common_sequence).toBeDefined();
            expect(patternResponse.body.proven_adaptations).toContain('parameter_adjustment');
          });
        });
        
        describe('Performance Benchmarks', () => {
          test('vector similarity search should complete under 500ms', async () => {
            // Create test data with embeddings
            await createTestDataWithEmbeddings(1000); // 1k records
            
            const queryVector = await embeddings.generate('test query');
            
            const startTime = Date.now();
            const response = await request(app)
              .post('/api/search/semantic')
              .send({
                query_vector: queryVector,
                limit: 10
              });
            
            const duration = Date.now() - startTime;
            
            expect(response.status).toBe(200);
            expect(duration).toBeLessThan(500);
            expect(response.body.results).toHaveLength(10);
          });
        });
      });
      
      // Test utilities
      async function createTestPath() {
        const response = await request(app)
          .post('/api/paths')
          .send({
            what: 'Test path',
            works: [],
            metrics: ['Test completed']
          });
        return response.body.path_id;
      }
      
      async function createTestDataWithEmbeddings(count) {
        for (let i = 0; i < count; i++) {
          const embedding = await embeddings.generate(`test content ${i}`);
          await db.query(`
            INSERT INTO works (what, how, metrics, what_vector)
            VALUES ($1, $2, $3, $4)
          `, [`Test work ${i}`, ['step 1'], ['metric 1'], embedding]);
        }
      }
    
    test_fixtures: |
      // Test Data Fixtures
      
      const testWorks = [
        {
          what: 'Setup Node.js project',
          how: ['Create package.json', 'Install dependencies', 'Setup test structure'],
          metrics: ['Package.json created', 'Dependencies installed', 'Tests runnable']
        },
        {
          what: 'Setup database schema',
          how: ['Create tables', 'Add indexes', 'Insert seed data'],
          metrics: ['All tables exist', 'Indexes created', 'Seed data loaded']
        },
        {
          what: 'Implement API endpoints',
          how: ['Define routes', 'Add validation', 'Add error handling'],
          metrics: ['All routes respond', 'Validation works', 'Errors handled']
        }
      ];
      
      const testPaths = [
        {
          what: 'Complete project setup',
          works: ['setup-nodejs-project', 'setup-database-schema'],
          metrics: ['Project fully initialized']
        },
        {
          what: 'API development',
          works: ['setup-nodejs-project', 'implement-api-endpoints'],
          metrics: ['API fully functional']
        }
      ];
      
      const testTideOutcomes = [
        {
          outcome: 'success',
          execution: { 'work1': 'completed', 'work2': 'completed' },
          adaptations: [],
          learnings: 'Execution went as planned'
        },
        {
          outcome: 'partial', 
          execution: { 'work1': 'completed', 'work2': 'failed' },
          adaptations: [{ type: 'sequence_change', reason: 'Work2 prerequisites missing' }],
          learnings: 'Dependencies must be checked before execution'
        },
        {
          outcome: 'failed',
          execution: { 'work1': 'failed' },
          adaptations: [{ type: 'tool_substitution', reason: 'Required tool not available' }],
          learnings: 'Environment validation should happen first'
        }
      ];
    
    performance_tests: |
      // Performance Benchmark Tests
      
      describe('Performance Benchmarks', () => {
        
        beforeAll(async () => {
          // Warm up database
          await db.query('ANALYZE');
        });
        
        test('Work creation should complete under 100ms', async () => {
          const times = [];
          
          for (let i = 0; i < 10; i++) {
            const start = Date.now();
            await request(app)
              .post('/api/works')
              .send({
                what: `Performance test work ${i}`,
                how: ['step 1'],
                metrics: ['metric 1']
              });
            times.push(Date.now() - start);
          }
          
          const avgTime = times.reduce((a, b) => a + b) / times.length;
          expect(avgTime).toBeLessThan(100);
        });
        
        test('Semantic search scales with data size', async () => {
          const dataSizes = [100, 500, 1000, 5000];
          const results = {};
          
          for (const size of dataSizes) {
            await createTestDataWithEmbeddings(size);
            
            const queryVector = await embeddings.generate('test query');
            const start = Date.now();
            
            await request(app)
              .post('/api/search/semantic')
              .send({ query_vector: queryVector, limit: 10 });
            
            results[size] = Date.now() - start;
            
            // Clean up
            await db.query('TRUNCATE TABLE works');
          }
          
          // Performance should not degrade significantly
          expect(results[5000]).toBeLessThan(results[100] * 3);
        });
      });
    
    error_scenario_tests: |
      // Error Scenario Tests
      
      describe('Error Scenarios', () => {
        
        test('should handle database connection loss gracefully', async () => {
          // Simulate connection loss
          await db.end();
          
          const response = await request(app)
            .get('/api/works')
            .expect(503);
          
          expect(response.body.error).toContain('database unavailable');
          
          // Restore connection
          await db.connect();
        });
        
        test('should validate vector dimensions', async () => {
          const response = await request(app)
            .post('/api/works')
            .send({
              what: 'Test work',
              how: ['step 1'],
              metrics: ['metric 1'],
              what_vector: new Array(512).fill(0.1) // Wrong dimension
            });
          
          expect(response.status).toBe(400);
          expect(response.body.error).toContain('vector dimension');
        });
        
        test('should handle embedding service failures', async () => {
          // Mock embedding service failure
          const originalGenerate = embeddings.generate;
          embeddings.generate = jest.fn().mockRejectedValue(new Error('Service unavailable'));
          
          const response = await request(app)
            .post('/api/works')
            .send({
              what: 'Test work',
              how: ['step 1'],
              metrics: ['metric 1']
            });
          
          expect(response.status).toBe(201); // Should still create work
          expect(response.body.what_vector).toBeNull(); // Vector should be null
          
          // Restore
          embeddings.generate = originalGenerate;
        });
      });