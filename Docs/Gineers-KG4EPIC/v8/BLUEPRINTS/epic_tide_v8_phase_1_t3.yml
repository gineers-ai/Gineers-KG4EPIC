# BLUEPRINT: KG4EPIC v8 Passive Storage System - PHASE 1
# Third attempt (t3) - CORRECTED to be passive storage only
# NO workflow orchestration, NO process management, ONLY storage/retrieval

BLUEPRINT:
  # === METADATA ===
  slug: "kg4epic-v8-passive-storage-t3"
  name: "KG4EPIC v8 Passive Storage System"
  
  # === PHASE MANAGEMENT ===
  phase:
    number: 1
    previous_phase_slug: null  # Fresh start
    goal_change: false
  
  # === HUMAN SECTION (Vision & Goals) ===
  vision: |
    Build a v8-compliant PASSIVE document storage and retrieval system.
    KG4EPIC is ONLY responsible for storing and retrieving documents.
    It does NOT handle workflow, confirmations, translations, or process flow.
    
    In the overall architecture:
    - Claude Code (C) handles workflow and orchestration
    - MCP Server (M) provides the interface
    - KG4EPIC (G) is the passive storage backend
    
    KG4EPIC simply:
    - Receives documents via MCP tools (blueprint-save, execution-save, etc.)
    - Stores them with proper embeddings for semantic search
    - Returns them when queried (blueprint-get, pattern-search, etc.)
    - Updates them when requested (execution-update, evidence-add)
  
  goals:
    - "Implement v8 document storage schema (blueprints, executions, evidence, patterns)"
    - "Provide MCP-compatible CRUD operations via /api/tool endpoint"
    - "Enable semantic search with proper embeddings (E5 for metadata, Ada-002 for content)"
    - "Store documents exactly as received (no validation, no workflow logic)"
    - "Return documents in MCP response format"
  
  # === AI SECTION (Technical Interpretation) ===
  scope: |
    A pure passive storage system with:
    - PostgreSQL database with v8 tables for document storage
    - Single /api/tool endpoint accepting MCP tool requests
    - CRUD operations for blueprints, executions, evidence, patterns
    - Semantic search using dual embeddings (E5 + Ada-002)
    - No workflow logic, no confirmations, no translations
    - No process orchestration, no state management beyond storage
    - Simply store what's given, return what's asked
  
  constraints:
    technical:
      database: "PostgreSQL 15 with pgvector extension"
      schema: "v8 tables adapted for pure storage"
      deployment: "Docker Compose (postgres, embeddings-e5, embeddings-ada002, api)"
      api_style: "Single /api/tool endpoint for MCP compatibility"
      embeddings:
        light: "E5-large-v2 (1024d) for names, tags, summaries"
        heavy: "text-embedding-ada-002 (1536d) for full content"
      mcp_requirements:
        endpoint: "/api/tool (POST only)"
        request_format: '{"tool": "tool-name", "arguments": {...}}'
        response_format: '{"success": bool, "result": {"content": [...]}}'
        error_codes: ["REQUIRED_FIELD_MISSING", "ENTITY_NOT_FOUND", "INVALID_FORMAT", "DATABASE_ERROR"]
      performance:
        storage_latency: "< 100ms"
        retrieval_latency: "< 50ms"
        search_latency: "< 200ms"
        max_document_size: "10MB"
        max_batch_size: "100 documents"
    
    resources:
      existing:
        - "Docker Compose infrastructure"
        - "E5 embeddings service (port 8000)"
        - "Ada-002 embeddings service (port 8001)"
        - "PostgreSQL with pgvector"
      needed:
        - "MCP tool gateway for CRUD"
        - "Embedding pipeline for incoming documents"
      
    boundaries:
      must_not:
        - "NO workflow orchestration"
        - "NO confirmation logic"
        - "NO translation services"
        - "NO state machines"
        - "NO process management"
        - "NO validation beyond basic field presence"
      must:
        - "Store any document given"
        - "Return documents when queried"
        - "Update documents when requested"
        - "Generate embeddings for search"
  
  works:
    # === DATABASE FOUNDATION ===
    
    drop_legacy_schema:
      purpose: "Remove old v5.1 tables to start fresh"
      verification:
        - "Old tables (phases, paths, tides, works) dropped"
        - "pgvector extension preserved"
    
    create_storage_schema:
      purpose: "Create v8 storage tables with specific schema"
      verification:
        - "blueprints: id(uuid), slug(varchar), name(varchar), yaml_content(text), metadata(jsonb), tags(text[]), embedding_name(vector1024), embedding_content(vector1536), created_at, updated_at"
        - "executions: id(uuid), blueprint_id(uuid), tide_number(int), status(varchar), content(jsonb), embedding_summary(vector1536), created_at, updated_at"
        - "evidence: id(uuid), execution_id(uuid), work_key(varchar), evidence_type(varchar), content(jsonb), artifacts(jsonb), created_at"
        - "patterns: id(uuid), problem(text), solution(text), applicability_score(float), embedding_problem(vector1536), embedding_solution(vector1536), usage_count(int), created_at"
        - "Indexes: btree on slugs, ivfflat on all vector columns, gin on jsonb fields"
    
    # === MCP TOOL GATEWAY ===
    
    implement_tool_router:
      purpose: "Create /api/tool endpoint that routes to handlers"
      verification:
        - "POST /api/tool accepts {tool, arguments}"
        - "Returns {success, result} or {success, error}"
        - "Routes to appropriate handler by tool name"
        - "No authentication required (passive storage)"
    
    implement_storage_tools:
      purpose: "Create handlers for document storage operations"
      verification:
        - "blueprint-save: Store blueprint with embeddings"
        - "blueprint-get: Retrieve by id or slug"
        - "blueprint-list: Return all blueprints"
        - "blueprint-search: Semantic search on blueprints"
        - "execution-save: Store execution"
        - "execution-update: Update execution content"
        - "execution-get: Retrieve by id"
        - "evidence-add: Add evidence to execution"
        - "pattern-save: Store pattern"
        - "pattern-search: Find similar patterns"
        - "health-check: Return system status"
        - "validate-structure: Check document format (no business logic)"
    
    # === EMBEDDING PIPELINE ===
    
    create_embedding_generator:
      purpose: "Generate embeddings when documents are saved"
      verification:
        - "Extract metadata fields (name, tags, summary)"
        - "Generate E5 embeddings for metadata"
        - "Generate Ada-002 embedding for full content"
        - "Store both embeddings with document"
    
    implement_dual_search:
      purpose: "Enable semantic search with both embedding types"
      verification:
        - "Metadata search uses E5 embeddings"
        - "Content search uses Ada-002 embeddings"
        - "Combined search with weighted scores"
        - "Returns documents sorted by similarity"
    
    # === STORAGE OPERATIONS ===
    
    implement_crud_operations:
      purpose: "Basic Create, Read, Update, Delete for all document types"
      verification:
        - "CREATE: Accept document, generate embeddings, store"
        - "READ: Retrieve by id, slug, or criteria"
        - "UPDATE: Replace content, regenerate embeddings"
        - "DELETE: Soft delete with deleted_at timestamp"
    
    handle_document_metadata:
      purpose: "Store and index document metadata for filtering"
      verification:
        - "Extract and store: author, version, tags, status"
        - "Enable filtering by metadata fields"
        - "Support range queries on timestamps"
        - "No business logic, just storage"
    
    # === RESPONSE FORMATTING ===
    
    format_mcp_responses:
      purpose: "Ensure all responses follow MCP format"
      verification:
        - "Success responses have result.content array"
        - "Error responses have error string"
        - "Content items have type and text fields"
        - "Consistent format across all tools"
    
    # === TESTING ===
    
    test_storage_operations:
      purpose: "Verify all storage operations work correctly"
      verification:
        - "Save document → generates embeddings → stores"
        - "Get document → returns with metadata"
        - "Search → returns similar documents"
        - "Update → replaces content and embeddings"
    
    test_mcp_compliance:
      purpose: "Ensure MCP format compliance"
      verification:
        - "Request format validated"
        - "Response format correct"
        - "Error handling follows MCP spec"
        - "All tools accessible via /api/tool"
  
  success_criteria:
    - "PostgreSQL schema for passive document storage"
    - "Single /api/tool endpoint handling all operations"
    - "MCP request/response format strictly followed"
    - "Documents stored exactly as received"
    - "Embeddings generated automatically on save"
    - "Semantic search working with dual embeddings"
    - "NO workflow logic or process orchestration"
    - "Pure passive storage system"
  
  evidence_required:
    - "Database schema showing simple storage tables"
    - "MCP tool request/response examples"
    - "Document save with auto-generated embeddings"
    - "Semantic search results showing similarity scores"
    - "CRUD operations via /api/tool"
    - "Docker compose with 4 services running"
    - "No workflow or confirmation logic in codebase"
  
  # === METADATA FOR AI ===
  for_ai: |
    CRITICAL: KG4EPIC is a PASSIVE STORAGE SYSTEM ONLY
    
    It does NOT:
    - Manage workflow or process flow
    - Handle confirmations or approvals
    - Translate blueprints to executions
    - Orchestrate EPIC-TIDE methodology
    - Validate business logic
    - Enforce state transitions
    
    It ONLY:
    - Stores documents (blueprints, executions, evidence, patterns)
    - Generates embeddings for semantic search
    - Returns documents when queried
    - Updates documents when requested
    
    Think of it as a smart database with semantic search, NOT a workflow engine.
    
    MCP Tools to implement (all CRUD only):
    - blueprint-save, blueprint-get, blueprint-list, blueprint-search
    - execution-save, execution-update, execution-get, execution-list
    - evidence-add, evidence-get, evidence-list
    - pattern-save, pattern-search, pattern-get
    
    Embedding strategy:
    - E5 for: document name, tags, summary (light metadata)
    - Ada-002 for: full document content (heavy text)
    
    The workflow (CONFIRM, TRANSLATOR, etc.) happens in Claude Code, NOT here.
    KG4EPIC just stores what it's given and returns what it's asked for.